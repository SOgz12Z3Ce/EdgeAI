# 深度学习

深度学习是指以深度神经网络为模型学习，应该是当下最流行的机器学习方法。从这里开始可以看见许多很令人熟悉的内容。

## 神经网络

神经网络（Neural Network）的字面意义揭示了它的灵感来源，也就是人脑那样各个神经元连接成的网络。从现在的眼光来看，神经网络和生物的“神经网络”差别其实挺大，不过这不影响神经网络确实很好用。

### 结构

神经网络由许多神经元（节点）、连接（权重）、非线性激活函数组成[^deep_learning_bias]，可以想象它们模拟了生物神经网络中的神经元、树突轴突、神经元内部规则。虽然不要求一定是分层的，但分层的网络很常见。分层的神经网络中的一层就是：

[deep_learning_bias]: 也可以带上偏置，不过偏置也可以看成一个孤立的神经元加上一条值为 1 的权重。

- 节点
- 连接上一层的权重
- 偏置
- 激活函数

层可以分为输入层、隐藏层、输出层，它们的含义也很简单：输入层和输出层就是最靠近输入特征和输出特征处的层，隐藏层就是它们中间的那些层。

权重可以理解成一个节点有多关注某个上层节点的值，而偏置则表示了这样的关注积累到多少程度才能“激活”这个神经元。

### 多层感知机

神经网络的经典例子是多层感知机（Multilayer Perceptron，MLP）。它的结构很简单，有至少一个隐藏层，层之间的神经元都有连接。

多层感知机的结构十分直白，没有作出任何假设与暗示，所有输入的特征都是平等的。所以多层感知机可以处理输入特征之间没啥明显，可以列成表格的问题，比如经典的房价预测。但是在输入特征之间有关系时可能不能很好地强调这些关系，如图像处理可能就表现不佳。另外，由于 MLP 的输入和输出维度都是固定的，许多输入规模可变的问题（如文本预测）不能由 MLP 单独解决。

尽管 MLP 本身能力不强，但经常作为组件参与到其他网络中。经典的 Transformer 中的注意力层后面就有一个 MLP，给网络提供非线性性。

### 卷积神经网络

用多层感知机处理图像有一些问题：

- 如果图像尺寸较大，参数量实在过于庞大。
- 不强调图像的局部特征。
- 同样的图像出现在不同位置时，结果可能有很大变动。

卷积神经网络用来解决这些问题。它有：

- 卷积层：先在图像上用数个卷积核滑动来提取特征。
- 激活层：引入非线性。
- 池化层：降采样，减少计算量。
- 全连接层：类似多层感知机，输出结果。

多出来的卷积层和池化层大大减少了参数量。

#### 卷积

卷积是一种很简单的计算：直观来讲，卷积核是一个矩阵，把它和图片左上角对齐，重合元素相乘求和，滑动这个卷积核，求得的值再组成一个矩阵就是卷积的结果。这个矩阵的元素也可以看成神经元，这些神经元只受到卷积核覆盖的那一小部分图像影响，这个区域叫做神经元的**感受野**。更深层的神经元也只受一部分图像影响，这些区域也叫这个神经元的感受野。“野”是视野的意思。

这么卷积一次的输出肯定会小一圈，如果想避免这个，可以在图像边缘**填充**一圈 0。卷积也不一定要一个一个像素滑动，每次滑动也可以移动多个像素，这个值叫做**步长**

卷积在数学上的定义要翻转过来，在这儿可以不管它。

#### 池化

池化这个名字估计是翻译时没用心，“pool”有汇聚、聚集的意思，池化就是指将一片特征图的主要特征提取出来。

常见的池化：

- 最大池化：在窗口内取最大值，可以保留边缘、纹理等显著特征。
- 平均池化：在窗口内取平均值，可以减少噪声。
- 全局池化：对整个特征图做池化，可以生成分类向量。
- Lp 池化：在窗口内取 Lp 范数，p=1 时平均池化，p $\to\inf$ 时最大池化。折中方案。
- 随机池化：在窗口内按权重随机选一个，有正则化效果。

#### 激活

神经网络都需要适时引入非线性，免得一堆线性变换瞎忙活。激活层就是提供非线性的。

卷积层是线性变换，不过池化层看起来有些方法是非线性的，为什么还是需要激活层呢？原因是这种非线性不够强，整体结果还是倾向于线性变换。

### 前向传播

神经网络其实组成了一张计算图，把值从输入层带入后，我们可以在下一层计算：

$$
h_j = sigma( sum_{i=1 to n} (w_ji * x_i) + b_j )
$$

并重复此过程，直到得出输出。这就是一次前向传播。

当应用神经网络时，其实也就是说让网络经历一次前向传播。前向传播的作用不只是算出输出值，它会顺便算出计算图中每一部分的值，为梯度下降时求导提供其需要的值。

### 反向传播

反向传播就是在完成一次前向传播后，逐步计算各个参数对损失函数的导数值。

为什么叫“反向”传播呢？因为损失函数靠近输出层，求导需要从输出层开始计算，而每一层的导数值依赖于下一层（链式法则）。从输入到输出是在“前向”传播，这个过程从输出到输入，自然就是“反向”传播了。

反向传播算出的导数值可以用于梯度下降，这是模型得以学习的关键。

### 梯度下降算法

想象一片山地，想要走到最高处，可以尝试每一步都往上走直到一个山顶。梯度下降算法基本上就是这么干的，不过神经网络一般要最小化损失函数，所以是“下降”，而参数对损失值的导数其实就是“梯度”。

这种算法显然不完美，就像一片山地不会只有一个山顶，梯度下降算出来的极值点也不一定是最值点，但是实践表明，只要处理得当，梯度下降其实不太容易陷入这种境地。实际问题中的参数一般非常多，参数空间的维度很高，就像是在高维空间中爬山可以往很多方向走，所以其实不容易陷入局部最优。

梯度下降法的基本操作是在一次反向传播后，用导数值更新参数：

$$
\theta \to \theta - \eta \frac{\partial L}{\partial \theta}
$$

其中 $\theta$ 是参数，$\eta$ 是学习率，用来控制参数调整的步幅。

#### 变体

上面的公式可以告诉我们如何用一个样本来调整参数，但实际工程中不只有这一种做法，下面有一些梯度下降的变体。

梯度下降的变体相当繁多，它们也许并没有数学上的严格证明作为支撑，但机器学习是一门实践跑得比理论快的学科，也许想象力有多强，这些方法就有多少。

##### 随机化

计算所有样本的梯度并取平均并调参就是常说的**梯度下降**（Gradient Descent，GD）。也可以只取一批样本作梯度下降，这就是**随机梯度下降**（Stochastic Gradient Descent，SGD），这里的“随机”指的不是随机调整参数，而是随机取样。

随机梯度下降添加了噪声，允许模型在更大胆的范围内调参，这对模型离开鞍点有帮助。

##### 动量

带动量的梯度下降会额外参考上一次移动的步幅，例如：

$$
v_t = \beta v_{t-1} + (1 - \beta)\nabla f(\theta_t)
\theta_{t+1} = \theta_t - \eta v_t
$$

对比普通的梯度下降，它额外加权平均了上一步的步幅。

另外还有一个先预判一次移动的版本，就像有惯性一样：

$$
v_t = \beta v_{t-1} + \nabla f(\theta_t - \eta \beta v_{t-1})
\theta_{t+1} = \theta_t - \eta v_t
$$

##### 学习率调度

学习率 $\eta$ 也可以是在训练过程中动态变化的，根据需求的不同有：

- 分段：在训练的不同阶段逐步降低学习率。
- 平滑：例如在训练初期慢慢提升学习率，随后逐渐衰减。
- 循环：让学习率不断上升下降。
- 基于性能：训练同时在验证集上检查并动态调整学习率。

### 激活函数

神经网络必须有非线性的激活函数，否则和一个线性层没啥区别。之所以叫“激活函数”，是来自当时对生物神经元的理解：输入信号积累到某个阈值后，神经元会被“激活”。在神经网络里也是如此，上一层的神经元加权求和再加上偏置后，用激活函数来判定这个神经元是否要激活以及激活的强弱。

但是就单单从数学的角度来看，激活函数就是用来提供非线性的，尽管我们把它解释成“激活”这样的概念，但它具体做了什么很大程度上没法很好地解释。

激活函数种类很多，常见的有：

- Sigmoid：$\sigma(x) = \frac{1}{1 + e^{-x}}$
- Tanh：$\tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}$
- ReLU：$\text{ReLU}(x) = \max(0, x)$
- GELU：$\text{GELU}(x) = x \cdot \Phi(x)$

不同的激活函数理论上都“可以”用作激活函数，但是它们更擅长特定的场景：

- Sigmoid：二分类、输出层（解释为概率）
- Tanh：RNN
- ReLU：各种深度神经网络
- GELU：NLP

比较令人惊讶的是，ReLU 应该是最简单的激活函数，但是却非常好用。

### 损失函数

损失函数或称代价函数是评估模型输出结果的函数。模型预测得越好，损失函数越小，训练模型就是最小化损失函数。

经典的损失函数及其作用有：

- 均方误差：一般的损失函数，对离群点惩罚大
- 交叉熵：预测概率分布常用

### 优化算法

优化算法是更新参数以最小化损失函数的算法。梯度下降及其变种都是优化算法，它们都可以逐步调整参数到收敛。除了梯度下降还有：

- 牛顿法：利用二阶导数信息，收敛更快。
- 进化算法：如遗传算法，模拟生物进化的过程，可以找到更适应的解。
- 贝叶斯优化：可以优化超参数，绕过代价太高昂的参数调整。

### 梯度消失与梯度爆炸

梯度消失和梯度爆炸是梯度下降中会遇到的问题。反向传播会将导数值不断相乘，久而久之容易把梯度过分缩小或者扩大。梯度消失时模型参数更新缓慢，欠拟合。梯度爆炸时模型参数更新过快，模型参数易发散，甚至产生溢出。

梯度消失与爆炸和激活函数与损失函数关系很密切。例如 Sigmoid 和 Tanh 在值较大时都很平缓，导数小，特别容易梯度消失。梯度消失与爆炸还可能是因为参数初始化方法不好、学习率不合适等。

梯度消失和梯度爆炸在深度学习这块尤其严重，背后的数学原理可能很深刻，但是我想从一个简单的角度来看：如果假设导数值是在 1 附近均匀分布的，在很多层的网络里，传播到靠前的层时，梯度会是多少？答案是趋近 0。股票先涨 50% 再跌 50%，总的来看跌了；先跌 50% 再涨 50%，总的来看还是跌了。更何况，现实里的导数值肯定不会这样均匀分布，如果它们总体比 1 小或者大，就容易梯度消失或爆炸，而即使它们在 1 附近均匀分布，还是容易梯度消失。也许如果不加以限制，网络梯度爆炸和消失才是常态。

### 正则化

正则化是用来对抗过拟合的，它是对模型的额外约束。正则化的形式很多样：

- L1 / L2 正则化：在损失函数上添加额外的项，惩罚参数过大的模型。
- Dropout：训练时故意把某些神经元设置成 0，不允许模型过分依赖某一个神经元。
- 早停：在模型开始过拟合之前停止训练。
- 数据增强：添加更多样本。

## 方向展望

深度学习本身只是工具，它可以被应用到不同的方向上，也需要不同的技能。

首先的首先，有些东西肯定是跑不掉的，不管哪个方向：

- 高数三件套：
  - 概率论
  - 微积分
  - 线性代数
- 工程实践：
  - Python
  - Python 框架：
    - PyTorch
    - TensorFlow
  - GPU 加速
- 也许还有 Transformer，这东西怎么到处都是？

### 强化学习

强化学习（Reinforcement Learning，RL）训练 AI 在特定环境下解决问题，比如下棋、玩游戏啥的。

额外需要的技能：

- 马尔可夫决策过程：把强化学习任务抽象成图，用多元组表示状态。学习的目标变为找到好的策略。这是建模强化学习问题的方法。
- 两种流派：
  - 值函数，学习一个 Q(状态, 动作) 函数，这个函数表明在某状态下执行一个动作获得的长期收益。有许多变种。
  - 策略梯度：类似梯度下降的策略学习方法。但是它的梯度没法直接算出来，只能采样并估计。
- 多智能体：联机游戏，学习合作与博弈。
- Gymnasium / Mujoco / IsaacGym：仿真环境工具，用来跑强化学习。
- 分布式学习：多线程学习。因为强化学习中要学习的材料不像监督学习那样现成，只能走一步看一步，而且状态总量太大。所以尤其需要分布式学习。

### 计算机视觉

计算机视觉（Computer Vision，CV）是解析图像和视频，也就是“让计算机拥有视觉”。它有非常多的子类，可以

我在不了解时似乎喜欢默认“图像无非就是一大串 RGB 值”，但图像处理是个严肃而复杂的话题，为了处理不同种类的图像并从中提取特征，其实有很多数字图像处理方法。

额外需要的技能：

- 数学（或者说，数字图像知识）：
  - 点：亮度、对比度、伽马……
  - 整体：平移、旋转、缩放、仿射变换……
  - 卷积：一种特殊的计算，可以提取和处理一小块图像。如模糊、边缘检测、锐化……相应地还有卷积神经网络，一种图像处理任务中表现更好的网络。
  - 颜色空间：RGB、HSV、Lab、YCrCb……
  - 傅里叶变换！
  - 二值图像（只有 0 和 1 的图像）或灰度图像的形态学操作。
  - ……
- 理论（不同领域的架构）：
  - 图像分类：ResNet
  - 目标检测：YOLO
  - 语义分割：FCN、U-Net、DeepLab
  - ……
  - Transformer 在各个领域中都有较新的应用，非常瞩目。
- 工程实践：
  - OpenCV：计算机视觉工具库，啥都有。

### 自然语言处理

自然语言处理（Natural Language Processing，NLP）让机器理解我们的语言。*Transformer的最初之作*。

额外需要的技能：

- 分词：不仅仅是按空格分开，词根词缀、标点符号也有某种语义，分词同时也处理它们。另外也用于处理中文这样没有空格的语言。
- Embedding：将词转换为特征的模型。
- 位置编码：将词的位置信息也转化为特征。
- PEFT：微调模型的方法，NLP 用的模型都尤其地大，重新训练全部参数不太实际。PEFT 包括 LoRA、QLoRA 等。
- 混合精度训练：选择性使用低精度浮点数作为参数训练，缓解参数量过大的问题。

### Sim2Real

当深度学习遇到现实世界。Sim2Real 把机器学习的成功应用到现实世界。也许是最综合的方向，要求强化学习、计算机视觉与机器人结合。

额外需要的技能：

- 前置：
  - 强化学习
  - 计算机视觉
- 模拟环境：
  - 动力学、力学……
  - 模拟传感器的性质：噪声、延迟、分辨率……
  - 仿真环境工具。
- 机器人（偏实践，子技能太多）
- 领域适应 / 域随机化：帮助模型适应模拟环境与现实世界的区别。
