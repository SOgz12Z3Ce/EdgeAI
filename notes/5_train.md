# 训练

监督学习时让模型从数据中学习，更新参数的过程就是训练（train）。一次训练一般经历这样的流程：

1. 收集数据并完成预处理
2. 划分训练集、验证集、测试集
3. 从训练集读取样本
4. 由模型给出预测
5. 比对预测与标签，计算损失值
6. 更新参数（取决于优化器，例如梯度下降）
7. 重复足够次数
8. 在验证集和测试集上评估模型

## 术语

先记录一些术语，它们在下面的记录中可能会用到。

### 数据

#### 特征

特征是一个比较抽象的概念，表示正在处理的对象的某方面信息。在输入处，一个特征的含义很清晰，身高、体重、性别等都可以经处理后作为特征输入模型。但模型中的许多层也包含许多高维向量，它们的每一维有时也称为一个“特征”，它们诚然也包含某方面的信息，但不一定可以被很好地解释了。

#### 标签

标签就是模型需要预测的答案。任何形式的监督学习都需要数据对应的标签，有了答案模型才得以学习其中的规律。

#### 样本

样本是一条数据的表达，是模型学习的基本对象。在监督学习中，样本是特征和对应的标签，无监督学习下当然不包含标签。

### 模型

#### 参数

参数是模型训练过程中可以调整的值，在不导致混淆的情况下，有时也说“权重”。

#### 超参数

超参数是描述模型本身的值，这里的“超”含义比较接近于“meta”，因为它决定了参数的规模。尽管超参数和参数一样是模型的一部分，也需要在训练过程中调整，但超参数显然不能在训练过程中自由变动，所以这两个概念会分离开。

### 评估

#### 欠拟合与过拟合

对于监督学习而言，无论何种任务都可以抽象为拟合一个向量到向量的函数，训练就可以被视为拟合这个函数。欠拟合就是模型“学艺不精”，和要拟合的函数差得远，还有调整参数的空间。过拟合就是模型太过关注每个样本的细节，以至于把噪声都拟合进去了。欠拟合和过拟合的模型都是不好的。

过拟合似乎比欠拟合更多地提起，毕竟欠拟合一般都可以通过加大网络复杂度、增加训练次数来解决。但网络过拟合时却不能反过来降低网络复杂度和训练次数，因为这样干的话网络会变弱，属于削足适履。数学上来看，在复杂度足够大时，过拟合一系列样本非常容易，比如各种插值法。

#### 模型容量

提及“容量”一词时，我常常想起英文中对应的“capacity”还有“才能”“潜力”的意思。模型容量其实也就是说模型的潜力有多大。

我喜欢想象模型就像一个能“装”规律和知识的容器，模型越复杂、规模越大，这个容器的容量就越大。

#### 泛化能力

泛化能力就是模型处理从未遇到过的数据的能力。过拟合的模型准确率高达百分百，但我们还是不喜欢它，就是因为它的泛化能力太差。测试集的一项功能就是检测模型的泛化能力。

## 数据预处理

我们讨论机器学习时，总是直接从最瞩目的模型、架构开始，心底里认为机器学习就是解决某种纯粹的数学问题。回过头来看，各种数据毕竟是来自现实世界的，在数据被收集上来时必然存在各种错误、遗漏、形式不便使用。数据预处理就是将这样的数据转化为机器学习可用的形式。

### 清洗

清洗的目的是剔除“脏”的数据，也就是有异常的数据，保证训练时用的数据有意义。数据被收集上来时，有可能因为很多现实问题而有异常，乱填调查问卷、转录错误或者单纯的处理失误，都可能产生异常。

清洗会关注和处理的异常值包括但不限于：

- 异常值
- 重复
- 格式（如各地的日期格式）
- 空行、乱码等错误


### 缺失值处理

有些数据可能不能被收集或不愿被提供，也可能单纯弄丢了。同样为了让训练时用的数据有意义，这些缺失值需要被填一个合理的值。这固然是妥协的结果，但技术上有时要求一条完整的数据，所以有必要处理缺失值。

缺失值处理的方法较为直白：

- 直接删除一整条数据（如果数据量够且缺失本身是随机发生的，或者整条数据都很异常）
- 填充均值、中位数或众数（随机缺失时）
- 如果缺失本身有特定含义，则标记“缺失”为特征（例如高收入人群倾向故意不填写收入信息）

### 数值缩放

数值缩放可以在保留数据分布特征的前提下抹去数据的其他差异，顺便消去量纲，确保模型不会因为数据形式的不同而“偏科”。例如，如果某模型需要输入身高作为一个特征，动辄 100 的数值大小可能难以被处理，完成数值缩放后可以避免这种问题。

#### 标准化

常用的一种标准化是 Z-Score 标准化，它可以让均值变为 0，方差变为 1：

$$
z = \frac{x - \mu}{\sigma}
$$

标准化本身也是机器学习里常用的技巧，主要目的是让参数保持在合理范围内，不引发梯度爆炸或消失。

#### 归一化

归一化通常是把数据缩放到固定区间，如

$$
z = \frac{x - x_{\min}}{x_{\max} - x_{\min}}
$$

### 特征工程

上面都是对数据的处理，而我们一般认为模型是从特征中学到东西的，直接把数据捆成一个向量塞到模型里则不太行。特征工程就是把数据加工成模型易于使用的特征。

特征工程有许多方法：

- 特征选择，如剔除和问题没啥关系的特征
- 特征构造，将数据组合为信息量更大的新特征
- 特征编码，如 one-hot 向量
- 特征降维，保留信息并减少特征维数

## 训练集、验证集、测试集

数据处理完成后，一般会按一定比例随机划分为训练集、验证集、测试集。它们本身都只是一堆数据，区别在于使用它们的方式。

- 训练集：模型学习（拟合）的数据，参与更新参数。
- 验证集：检查模型表现用的数据，确定合适的超参数和停止时机等。
- 测试集：最终测试用的数据，评估模型效果，尤其是泛化能力。

在平常的科普中经常只提到训练集和测试集，但在工程实践中常常还需要验证集来调整(超参数)[#超参数]。试想在为实际问题训练模型时，学习率、批大小、训练轮数等超参数的最优取值是未知的，如果不存在验证集，直接在测试集上调整超参数，那就*用超参数悄悄过拟合了*，所以验证集是有必要的。

## 模型评估

模型评估要回答“什么样的模型是好的？”这个问题比看上去要复杂。比如拟合到 100% 准确的模型不一定是最好的模型，因为它可能过拟合也即过分关注训练集中的噪声，泛化能力太差。

例如二分类问题中，模型评估会关心这些指标：

- 准确性（正确率）
- 精确率与召回率（预测为正的样本中，确实为正的样本数量；预测为负的样本中，确实为负的样本数量）
- F1 分数（精确率与召回率的调和平均）
- ROC 曲线及其 AUC 

回归问题中有：

- 误差（平均绝对误差、均方误差等）
- 决定系数（R 方）

从更广阔的角度来看，模型评估还可以包括效率、可解释性、稳定性等。
